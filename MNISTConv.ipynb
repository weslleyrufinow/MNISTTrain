{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import random\n",
    "import copy\n",
    "import numpy as np\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import optimizer\n",
    "from torchvision import datasets, transforms\n",
    "from matplotlib import pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "MNIST = datasets.MNIST(root=\".\",\n",
    "                       train=True,\n",
    "                       transform = transforms.ToTensor(),\n",
    "                       download=False)\n",
    "\n",
    "MNIST_VAL = datasets.MNIST(root=\".\",\n",
    "                           train=False,\n",
    "                           transform = transforms.ToTensor(),\n",
    "                           download=False)                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 28, 28])\n",
      "torch.Size([60000, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "dado, rotulo = MNIST[0]\n",
    "print(dado.size())\n",
    "print(MNIST.data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = DataLoader(MNIST, batch_size=64)\n",
    "dataloader_val = DataLoader(MNIST_VAL, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(\n",
    "    nn.Conv2d(1, 20, 5),\n",
    "    nn.MaxPool2d(2, stride=2),\n",
    "    nn.Conv2d(20, 50, 5),\n",
    "    nn.MaxPool2d(2, stride=2),\n",
    "    nn.Flatten(),\n",
    "    nn.Linear(800, 500),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(500, 10),\n",
    "    nn.Softmax(dim=1)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def achatar(X):\n",
    "    batch_size = X.size(0)\n",
    "    flattened_X = X.view(batch_size, -1)\n",
    "    return flattened_X\n",
    "\n",
    "def permutar(images):\n",
    "    permuted_images = images.clone()\n",
    "    for i in range(images.size(0)):\n",
    "        image = images[i]\n",
    "        permuted_indices = torch.randperm(image.numel())\n",
    "        permuted_image = image.view(-1)[permuted_indices].view(image.size())\n",
    "        permuted_images[i] = permuted_image\n",
    "    return permuted_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch(0:0): [Loss: 2.30]\n",
      "Epoch(0:6400): [Loss: 2.21]\n",
      "Epoch(0:12800): [Loss: 2.29]\n",
      "Epoch(0:19200): [Loss: 2.31]\n",
      "Epoch(0:25600): [Loss: 2.23]\n",
      "Epoch(0:32000): [Loss: 2.29]\n",
      "Epoch(0:38400): [Loss: 2.07]\n",
      "Epoch(0:44800): [Loss: 2.25]\n",
      "Epoch(0:51200): [Loss: 2.26]\n",
      "Epoch(0:57600): [Loss: 2.10]\n",
      "Test error: \n",
      " Accuracy 9.87%\n",
      "Epoch(1:0): [Loss: 2.16]\n",
      "Epoch(1:6400): [Loss: 2.15]\n",
      "Epoch(1:12800): [Loss: 2.22]\n",
      "Epoch(1:19200): [Loss: 2.31]\n",
      "Epoch(1:25600): [Loss: 2.19]\n",
      "Epoch(1:32000): [Loss: 2.26]\n",
      "Epoch(1:38400): [Loss: 2.14]\n",
      "Epoch(1:44800): [Loss: 2.24]\n",
      "Epoch(1:51200): [Loss: 2.27]\n",
      "Epoch(1:57600): [Loss: 2.13]\n",
      "Test error: \n",
      " Accuracy 10.09%\n",
      "Epoch(2:0): [Loss: 2.17]\n",
      "Epoch(2:6400): [Loss: 2.18]\n",
      "Epoch(2:12800): [Loss: 2.24]\n",
      "Epoch(2:19200): [Loss: 2.28]\n",
      "Epoch(2:25600): [Loss: 2.21]\n",
      "Epoch(2:32000): [Loss: 2.28]\n",
      "Epoch(2:38400): [Loss: 2.11]\n",
      "Epoch(2:44800): [Loss: 2.26]\n",
      "Epoch(2:51200): [Loss: 2.26]\n",
      "Epoch(2:57600): [Loss: 2.07]\n",
      "Test error: \n",
      " Accuracy 9.90%\n",
      "Epoch(3:0): [Loss: 2.20]\n",
      "Epoch(3:6400): [Loss: 2.16]\n",
      "Epoch(3:12800): [Loss: 2.20]\n",
      "Epoch(3:19200): [Loss: 2.26]\n",
      "Epoch(3:25600): [Loss: 2.19]\n",
      "Epoch(3:32000): [Loss: 2.27]\n",
      "Epoch(3:38400): [Loss: 2.12]\n",
      "Epoch(3:44800): [Loss: 2.24]\n"
     ]
    }
   ],
   "source": [
    "learningRate = 0.001\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr=learningRate)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "epochs = 10\n",
    "\n",
    "for e in range(epochs):\n",
    "    #LOOP DE TREINAMENTO\n",
    "    for i, (X, y) in enumerate(dataloader):\n",
    "        X = permutar(X)\n",
    "        yhat = model(X)\n",
    "        loss = loss_fn(yhat, y)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        lossvalue, pos = loss.item(), i * len(X)\n",
    "        if i % 100 == 0:\n",
    "            print(f\"Epoch({e}:{pos}): [Loss: {lossvalue:.2f}]\")\n",
    "    #LOOP DE TESTE\n",
    "    tloss = 0.0\n",
    "    correct = 0.0\n",
    "    size = len(dataloader_val.dataset)\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader_val:\n",
    "            pred = model(X)\n",
    "            tloss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "        print(f\"Test error: \\n Accuracy {100 * (correct/size):2.2f}%\")\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

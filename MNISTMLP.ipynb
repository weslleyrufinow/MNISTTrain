{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import random\n",
    "import copy\n",
    "import numpy as np\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import optimizer\n",
    "from torchvision import datasets, transforms\n",
    "from matplotlib import pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "MNIST = datasets.MNIST(root=\".\",\n",
    "                       train=True,\n",
    "                       transform = transforms.ToTensor(),\n",
    "                       download=False)\n",
    "\n",
    "MNIST_VAL = datasets.MNIST(root=\".\",\n",
    "                           train=False,\n",
    "                           transform = transforms.ToTensor(),\n",
    "                           download=False)                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 28, 28])\n",
      "torch.Size([60000, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "dado, rotulo = MNIST[0]\n",
    "print(dado.size())\n",
    "print(MNIST.data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = DataLoader(MNIST, batch_size=64)\n",
    "dataloader_val = DataLoader(MNIST_VAL, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLPLeakyReLU(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MLPLeakyReLU, self).__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(784, 10),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(10, 10),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Softmax(dim=1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)  \n",
    "\n",
    "#Instanciando a Rede Neural\n",
    "model = MLPLeakyReLU()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def achatar(X):\n",
    "    batch_size = X.size(0)\n",
    "    flattened_X = X.view(batch_size, -1)\n",
    "    return flattened_X\n",
    "\n",
    "def permutar(images):\n",
    "    permuted_images = images.clone()\n",
    "    for i in range(images.size(0)):\n",
    "        image = images[i]\n",
    "        permuted_indices = torch.randperm(image.numel())\n",
    "        permuted_image = image.view(-1)[permuted_indices].view(image.size())\n",
    "        permuted_images[i] = permuted_image\n",
    "    return permuted_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch(0:0): [Loss: 2.23]\n",
      "Test error: \n",
      " Accuracy 20.93%\n",
      "Epoch(1:0): [Loss: 2.21]\n",
      "Test error: \n",
      " Accuracy 20.17%\n",
      "Epoch(2:0): [Loss: 2.21]\n",
      "Test error: \n",
      " Accuracy 21.12%\n",
      "Epoch(3:0): [Loss: 2.20]\n",
      "Test error: \n",
      " Accuracy 21.25%\n",
      "Epoch(4:0): [Loss: 2.21]\n",
      "Test error: \n",
      " Accuracy 22.47%\n",
      "Epoch(5:0): [Loss: 2.20]\n",
      "Test error: \n",
      " Accuracy 21.75%\n",
      "Epoch(6:0): [Loss: 2.19]\n",
      "Test error: \n",
      " Accuracy 22.18%\n",
      "Epoch(7:0): [Loss: 2.19]\n",
      "Test error: \n",
      " Accuracy 21.90%\n",
      "Epoch(8:0): [Loss: 2.19]\n",
      "Test error: \n",
      " Accuracy 21.56%\n",
      "Epoch(9:0): [Loss: 2.19]\n",
      "Test error: \n",
      " Accuracy 21.41%\n"
     ]
    }
   ],
   "source": [
    "learningRate = 0.001\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr=learningRate)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "epochs = 10\n",
    "\n",
    "for e in range(epochs):\n",
    "    #LOOP DE TREINAMENTO\n",
    "    for i, (X, y) in enumerate(dataloader):\n",
    "        X = permutar(X)\n",
    "        X = achatar(X)\n",
    "        yhat = model(X)\n",
    "        loss = loss_fn(yhat, y)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        lossvalue, pos = loss.item(), i * len(X)\n",
    "        if i % 1000 == 0:\n",
    "            print(f\"Epoch({e}:{pos}): [Loss: {lossvalue:.2f}]\")\n",
    "    #LOOP DE TESTE\n",
    "    tloss = 0.0\n",
    "    correct = 0.0\n",
    "    size = len(dataloader_val.dataset)\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader_val:\n",
    "            X = achatar(X)\n",
    "            pred = model(X)\n",
    "            tloss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "        print(f\"Test error: \\n Accuracy {100 * (correct/size):2.2f}%\")\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
